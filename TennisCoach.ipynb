{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Performing Pose Estimation using AlphaPose**"
      ],
      "metadata": {
        "id": "tP0b07J1TS8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone repository:"
      ],
      "metadata": {
        "id": "HpTQ6gf2jCAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/christinathr2000/TennisCoach.git"
      ],
      "metadata": {
        "id": "8I9AbNXuQYqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37270bf4-efca-41ec-c3ca-958971e0ebe0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TennisCoach'...\n",
            "remote: Enumerating objects: 4949, done.\u001b[K\n",
            "remote: Counting objects: 100% (4742/4742), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3444/3444), done.\u001b[K\n",
            "remote: Total 4949 (delta 865), reused 4741 (delta 865), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (4949/4949), 75.84 MiB | 25.93 MiB/s, done.\n",
            "Resolving deltas: 100% (886/886), done.\n",
            "Updating files: 100% (4296/4296), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirements:"
      ],
      "metadata": {
        "id": "vI_8-FThjJ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/TennisCoach/AlphaPose"
      ],
      "metadata": {
        "id": "LIKa3O9CidHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05a91af-b2f1-476f-c491-4efa4048a669"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TennisCoach/AlphaPose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "aWGEI6Zbie3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097e35d4-4c43-430d-fe3a-2c7ebf9151c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.5/684.5 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.5/459.5 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.2/433.2 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.9/283.9 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.9/913.9 kB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for treelib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for coverage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for xhtml2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for svglib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks if GPU is available:"
      ],
      "metadata": {
        "id": "5lcp67wLjLTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "5YhfiWJuQYcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4a5751-cbfc-4dcf-8306-0b04a76b3941"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import boto3\n",
        "from botocore.exceptions import NoCredentialsError\n",
        "from botocore.config import Config\n",
        "\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = 'ACCESS_KEY_ID'\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = 'SECRET_ACCESS_KEY'\n",
        "os.environ['S3_BUCKET_NAME'] = 'ivu-cloud'\n",
        "\n",
        "s3_config = Config(\n",
        "    region_name='eu-central-1',\n",
        "    signature_version='s3v4'\n",
        ")\n",
        "s3_client = boto3.client(\n",
        "    's3',\n",
        "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
        "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
        "    config=s3_config\n",
        ")"
      ],
      "metadata": {
        "id": "4DXAZ4C6rag4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloads used SPPE and YOLO detector and stores in correct folder:** \\\\\n",
        "Lately, an access denied error occurs when using gdown, even though this should not happen.\n",
        "If you get that message, download the file at the shown link and add to\n",
        "/TennisCoach/AlphaPose/models/sppe folder.\\\\\n",
        "Below, you'll find a code snippet that served as our solution for the gdown error. We stored all the data on our drive and imported it from there. Feel free to follow the same approach."
      ],
      "metadata": {
        "id": "3Ah027tgjQ5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd models/sppe"
      ],
      "metadata": {
        "id": "Co5aFt5NikJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db34e85d-85f0-4141-9cf1-10d9f903356a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TennisCoach/AlphaPose/models/sppe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1OPORTWB2cwd5YTVBX-NE8fsauZJWsrtW\n",
        "# Lately, a access denied error occurs - even though this should not happen.\n",
        "# If you get that message, download the file at the shown link and add to /TennisCoach/AlphaPose/models/sppe folder"
      ],
      "metadata": {
        "id": "6P_Qf48OiurH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de159f21-5da9-4013-8f89-6c52af8065ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1OPORTWB2cwd5YTVBX-NE8fsauZJWsrtW\n",
            "From (redirected): https://drive.google.com/uc?id=1OPORTWB2cwd5YTVBX-NE8fsauZJWsrtW&confirm=t&uuid=583ae621-1c0f-4ee4-b4f7-b6e97714aa9e\n",
            "To: /content/TennisCoach/AlphaPose/models/sppe/duc_se.pth\n",
            "100% 239M/239M [00:06<00:00, 37.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../yolo"
      ],
      "metadata": {
        "id": "o66oIkTQivGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81177107-1c05-4989-f868-62cbeb3e551b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TennisCoach/AlphaPose/models/yolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC\n",
        "# Lately, a access denied error occurs - even though this should not happen.\n",
        "# If you get that message, download the file at the shown link and add to /TennisCoach/AlphaPose/models/yolo folder\n",
        "# or use cells underneath to get data from Google Drive"
      ],
      "metadata": {
        "id": "P6RTZWwPiyFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a53cb6-ac9c-4adc-bd2d-20ae9b89966e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC\n",
            "From (redirected): https://drive.google.com/uc?id=1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC&confirm=t&uuid=4b50263d-8de2-4502-b1ad-2e8242738646\n",
            "To: /content/TennisCoach/AlphaPose/models/yolo/yolov3-spp.weights\n",
            "100% 252M/252M [00:06<00:00, 36.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fanzuguFQb6z",
        "outputId": "6a9bc13a-25f8-4b87-c4b1-9e2f95a547cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "sppe_path = '/content/drive/My Drive/PersonalTennisCoach/duc_se.pth'\n",
        "new_sppe_path = '/content/TennisCoach/AlphaPose/models/sppe/'\n",
        "shutil.copy(sppe_path, new_sppe_path)\n",
        "\n",
        "yolo_path = '/content/drive/My Drive/PersonalTennisCoach/yolov3-spp.weights'\n",
        "new_yolo_path = '/content/TennisCoach/AlphaPose/models/yolo/'\n",
        "shutil.copy(yolo_path, new_yolo_path)"
      ],
      "metadata": {
        "id": "Bb2IVmKUQcr8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a0b5960-797c-46db-c47f-dbbb86c2aab2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/TennisCoach/AlphaPose/models/yolo/yolov3-spp.weights'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Enter Video Number:** \\\\\n",
        "We provide some test videos on our github and can be found in the input folder.\n",
        "Feel free to set video_nr to your selected number.\n",
        "\n",
        "If you uploaded your own video, simply set the video_name parameter"
      ],
      "metadata": {
        "id": "3LYG5t2CBqK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set when using own video\n",
        "video_name = \"video001.mp4\"\n",
        "# set when using video from input folder\n",
        "video_nr = 11"
      ],
      "metadata": {
        "id": "T1QdvYsorDJ7"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/TennisCoach/WebService/backend"
      ],
      "metadata": {
        "id": "fRVE9SyxMJOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from s3_utils import generate_download_url, generate_upload_url\n",
        "\n",
        "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
        "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
        "S3_BUCKET_NAME = os.getenv('S3_BUCKET_NAME')\n",
        "\n",
        "download_url = generate_download_url(S3_BUCKET_NAME, video_name, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, expiration=10)\n",
        "\n",
        "video_path = ''\n",
        "\n",
        "if download_url is not None:\n",
        "    response = requests.get(download_url)\n",
        "    if response.status_code == 200:\n",
        "        local_video_path = f'AlphaPose/input/{video_name}'\n",
        "        os.makedirs(os.path.dirname(local_video_path), exist_ok=True)\n",
        "        with open(local_video_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"Video downloaded successfully\")\n",
        "        video_path = local_video_path\n",
        "    else:\n",
        "        print(\"Failed to download the video\")\n",
        "        print(\"Using provided test video instead\")\n",
        "        long_nr = str('{:03d}'.format(video_nr))\n",
        "        video_path = 'input/video' + long_nr + '.mp4'\n",
        "else:\n",
        "    print(\"Failed to generate download URL\")\n",
        "    print(\"Using provided test video instead\")\n",
        "    long_nr = str('{:03d}'.format(video_nr))\n",
        "    video_path = 'input/video' + long_nr + '.mp4'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig3SRnhhqMgm",
        "outputId": "82650d52-f035-4d42-bbdc-9d8ed9573085"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download the video\n",
            "Using provided test video instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Video Preprocessing\n",
        "We check framerate, resolution and video format. \\\\\n",
        "The histogram equalization part is commented out because AlphaPose also did not use it during training.\n"
      ],
      "metadata": {
        "id": "0daMjDCTyNoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/TennisCoach/AlphaPose"
      ],
      "metadata": {
        "id": "3oc4uUS3iz4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b91625-27ab-41d9-de75-0e17105aab5e"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TennisCoach/AlphaPose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import magic\n",
        "\n",
        "def video_preprocessing(video_path):\n",
        "    #Check if file is mp4\n",
        "    file_type = magic.Magic().from_file(video_path)\n",
        "    if 'MP4' not in file_type.upper():\n",
        "      print(\"Error: The file format is not MP4.\")\n",
        "      return False\n",
        "\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not video.isOpened():\n",
        "        print(\"Error: Video file was not opened successfully\")\n",
        "        return False\n",
        "\n",
        "    # Get the frames per second (fps) of the video and check if minimum of 20 fps is met\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    if fps < 13:\n",
        "      print(\"Error: Frame rate is too low. A minimum rate of 20 fps is required.\")\n",
        "      video.release()\n",
        "      return False\n",
        "\n",
        "    #Check resolution of video\n",
        "    width = int(video.get(3))\n",
        "    height = int(video.get(4))\n",
        "    resolution = (width, height)\n",
        "\n",
        "    if (width < 300 or height < 300):\n",
        "      print(\"Error: Resolution is too small. A minimum resolution of 300x300 is needed.\")\n",
        "      video.release()\n",
        "      return False\n",
        "\n",
        "    #Perform histogram equalization to increase visibility ----------------------------\n",
        "    #https://www.geeksforgeeks.org/saving-a-video-using-opencv/\n",
        "    #We do not perform Histogram equalization anymore because AlphaPose also\n",
        "    #did not use it during training\n",
        "    # out_video_path = 'input/video' + long_nr + '_equal.mp4'\n",
        "    # out_file = cv2.VideoWriter(out_video_path, cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "    #                         fps, (width, height))\n",
        "    #Inspiration from: https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html\n",
        "    # while True:\n",
        "    #   ret, frame = video.read()\n",
        "    #   if not ret:\n",
        "    #     break\n",
        "    #   grey = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
        "    #   grey[:,:,0] = cv2.equalizeHist(grey[:,:,0])\n",
        "    #   rgb_equal = cv2.cvtColor(grey, cv2.COLOR_YCrCb2BGR)\n",
        "      #out_file.write(rgb_equal)\n",
        "\n",
        "    # Release video capture and writer objects\n",
        "    # video.release()\n",
        "    # out_file.release()\n",
        "    #-----------------------------------------------------------------------------------\n",
        "\n",
        "    # Closes all the frames\n",
        "    cv2.destroyAllWindows()\n",
        "    return True\n",
        "\n",
        "rvalue = video_preprocessing(video_path)\n",
        "if not rvalue:\n",
        "  print(\"Something went wrong, check the above error message before continuing.\")\n",
        "else:\n",
        "  print(\"Everything looks good!\")"
      ],
      "metadata": {
        "id": "DY6hwVPOyNDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc13799c-927a-4319-b3fc-0ec97140d62f"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything looks good!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pose Estimation is performed with AlphaPose"
      ],
      "metadata": {
        "id": "h80WAP7XjavY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python video_demo.py --video {} --outdir output --save_video --sp --vis_fast\".format(video_path)\n",
        "!{command}"
      ],
      "metadata": {
        "id": "OqWE-obXBCi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1541a962-f3af-49a4-a504-47e838633c77"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading YOLO model..\n",
            "Loading pose model from ./models/sppe/duc_se.pth\n",
            "100% 62/62 [00:06<00:00,  9.87it/s]\n",
            "===========================> Finish Model Running.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Phase Estimation of each frame"
      ],
      "metadata": {
        "id": "37dwROY100-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../PhaseDetection"
      ],
      "metadata": {
        "id": "hkhLs3ZmT1xj"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can ignore the warnings. They do not impact the following code."
      ],
      "metadata": {
        "id": "IRzv8n_rDNBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import VideoPhaseEstimator"
      ],
      "metadata": {
        "id": "A1OKSteiTBNp"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/TennisCoach/AlphaPose/\" + video_path\n",
        "video_phase_estimator = VideoPhaseEstimator.VideoPhaseEstimator()\n",
        "frame_phase = video_phase_estimator.estimate_phases(path)\n",
        "\n",
        "#store frame number for each phase in list for keypoint analysis\n",
        "start_nr = [idx for idx, v in enumerate(frame_phase) if v == 'start']\n",
        "trophy_nr = [idx for idx, v in enumerate(frame_phase) if v == 'loading']\n",
        "acc_nr = [idx for idx, v in enumerate(frame_phase) if v == 'acceleration']\n",
        "contact_nr = [idx for idx, v in enumerate(frame_phase) if v == 'contact']\n",
        "finish_nr = [idx for idx, v in enumerate(frame_phase) if v == 'finish']\n",
        "\n",
        "#To have time intervals for final annotated video\n",
        "print(frame_phase)\n",
        "s_start = min(start_nr) + (max(start_nr)-min(start_nr))/2 if min(start_nr) + (max(start_nr)-min(start_nr))/2 >= 0 else 0\n",
        "s_trophy = max(start_nr)\n",
        "s_acc = max(trophy_nr)\n",
        "s_contact = max(acc_nr)\n",
        "s_finish = max(contact_nr)\n",
        "e_finish = max(finish_nr)"
      ],
      "metadata": {
        "id": "TCygY6pFSNnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498a9e11-55aa-4e40-daac-675adc789efb"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TennisCoach/PhaseDetection\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-01-26 09:50:39] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "[2024-01-26 09:50:39] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_l\n",
            "[2024-01-26 09:50:40] INFO - checkpoint_utils.py - License Notification: YOLO-NAS-POSE pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS-POSE.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "[2024-01-26 09:50:41] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_pose_l\n",
            "[2024-01-26 09:50:42] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
            "[2024-01-26 09:50:46] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Find mistakes in each extracted phase:"
      ],
      "metadata": {
        "id": "w3eS0aJJ3HC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/TennisCoach/AlphaPose"
      ],
      "metadata": {
        "id": "y74rIpPuzBTd"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "#Have an array with error codes we can then use in the visualization to extract\n",
        "#bounding boxes around needed areas\n",
        "mistakes = []\n",
        "# Mistakes in Start Phase:\n",
        "#  0 - Left foot not in front of right foot\n",
        "#  1 - Feet are too close together\n",
        "#  2 - Feet are too far apart\n",
        "#  3 - Let your left arm dangle\n",
        "#  4 - Let your right arm dangle\n",
        "# Mistakes in Trophy Phase:\n",
        "#  5 - Right arm should be in a 90° angle - under 80°\n",
        "#  6 - Right arm should be in a 90° angle - over 100°\n",
        "#  7 - Left arm should be already above your head\n",
        "#  8 - Left arm should be more stretched\n",
        "#  9 - Bow your shoulder, hips and feet more\n",
        "# 10 - Bow your left and right body part equally\n",
        "# Mistakes in Acceleration Phase:\n",
        "# 11 - bow your shoulder, hips and feet more\n",
        "# 12 - bow your left and right body part equally\n",
        "# Mistakes in Contact Point Phase:\n",
        "# 13 - straight arm - angle between shoulder - elbow - wrist ~ 180°\n",
        "# 14 - stretch left leg more\n",
        "# 15 - stretch right leg more\n",
        "# Mistakes in Finish Phase:\n",
        "# 16 - bend knees more to protect knees (compared to contact point phase)\n",
        "\n",
        "def checkPosition():\n",
        "  with open('output/alphapose-results.json') as json_result:\n",
        "    data = json.load(json_result)  #list of dictionaries\n",
        "\n",
        "  #1. remove additional persons --------------------------------------------\n",
        "  #indices are added to list 'idx_to_remove'\n",
        "  idx_to_remove = []\n",
        "  for idx, dic in enumerate(data):\n",
        "    if idx > 0 and dic['image_id'] == data[idx-1]['image_id']:\n",
        "      for idx2 in range(idx-1, -1, -1):\n",
        "        if dic['image_id'] != data[idx2]['image_id']:\n",
        "          break\n",
        "        if idx2 in idx_to_remove:\n",
        "          continue\n",
        "        height_1 = max(data[idx2]['keypoints'][46] - data[idx2]['keypoints'][1], data[idx2]['keypoints'][49] - data[idx2]['keypoints'][1])\n",
        "        height_2 = max(dic['keypoints'][46] - dic['keypoints'][1], dic['keypoints'][49] - dic['keypoints'][1])\n",
        "        if(height_2 > height_1):\n",
        "          idx_to_remove.append(idx2)\n",
        "        else:\n",
        "          idx_to_remove.append(idx)\n",
        "        break\n",
        "\n",
        "  idx_to_remove = list(dict.fromkeys(idx_to_remove)) # remove duplicates\n",
        "  idx_to_remove.sort(reverse=True) #sorts indices in descending order - so we don't have an indexing error\n",
        "  #removes additional persons\n",
        "  for idx in idx_to_remove:\n",
        "    data.pop(idx)\n",
        "\n",
        "  with open('output/alphapose-results.json', \"w\") as json_file:\n",
        "    json.dump(data, json_file)\n",
        "\n",
        "  start_dicts, trophy_dicts, acc_dicts, contact_dicts, finish_dicts = [], [], [], [], []\n",
        "  for idx, dic in enumerate(data):\n",
        "    if idx in start_nr:\n",
        "      start_dicts.append(dic)\n",
        "    elif idx in trophy_nr:\n",
        "      trophy_dicts.append(dic)\n",
        "    elif idx in acc_nr:\n",
        "      acc_dicts.append(dic)\n",
        "    elif idx in contact_nr:\n",
        "      contact_dicts.append(dic)\n",
        "    elif idx in finish_nr:\n",
        "      finish_dicts.append(dic)\n",
        "\n",
        "  #-------------------------------------------------------------------------\n",
        "  #2. check start phase ----------------------------------------------------\n",
        "  # We concentrate on the analysis of videos taken from the right side and right-handed people\n",
        "  mistakes.extend([0,1,2,3,4])\n",
        "  for start_dict in start_dicts:\n",
        "    keypoints_start = start_dict['keypoints']\n",
        "    #keypoint order from https://github.com/MVIG-SJTU/AlphaPose/blob/master/docs/output.md\n",
        "    nose = (keypoints_start[0], keypoints_start[1])\n",
        "    left_eye = (keypoints_start[3], keypoints_start[4])\n",
        "    right_eye = (keypoints_start[6], keypoints_start[7])\n",
        "    left_ear = (keypoints_start[9], keypoints_start[10])\n",
        "    right_ear = (keypoints_start[12], keypoints_start[13])\n",
        "    left_shoulder = (keypoints_start[15], keypoints_start[16])\n",
        "    right_shoulder = (keypoints_start[18], keypoints_start[19])\n",
        "    left_elbow = (keypoints_start[21], keypoints_start[22])\n",
        "    right_elbow = (keypoints_start[24], keypoints_start[25])\n",
        "    left_wrist = (keypoints_start[27], keypoints_start[28])\n",
        "    right_wrist = (keypoints_start[30], keypoints_start[31])\n",
        "    left_hip = (keypoints_start[33], keypoints_start[34])\n",
        "    right_hip = (keypoints_start[36], keypoints_start[37])\n",
        "    left_knee = (keypoints_start[39], keypoints_start[40])\n",
        "    right_knee = (keypoints_start[42], keypoints_start[43])\n",
        "    left_ankle = (keypoints_start[45], keypoints_start[46])\n",
        "    right_ankle = (keypoints_start[48], keypoints_start[49])\n",
        "\n",
        "    #2.1. Left foot in front of right foot\n",
        "    if(left_ankle[0] > right_ankle[0]):\n",
        "      if 0 in mistakes:\n",
        "        mistakes.remove(0)\n",
        "\n",
        "    #2.2. Feet are approximately shoulder-width apart or slightly wider\n",
        "    #Transform x-y coordinates to cm with resolution\n",
        "    distance_feet_x = left_ankle[0] - right_ankle[0]\n",
        "    distance_feet_y = left_ankle[1] - right_ankle[1]\n",
        "    distance_feet = math.sqrt(distance_feet_x**2 + distance_feet_y**2)\n",
        "    distance_shoulder_x = left_shoulder[0] - right_shoulder[0]\n",
        "    distance_shoulder_y = left_shoulder[1] - right_shoulder[1]\n",
        "    distance_shoulder = math.sqrt(distance_shoulder_x**2 + distance_shoulder_y**2)\n",
        "\n",
        "    if distance_feet > distance_shoulder*1.1:\n",
        "      if 1 in mistakes:\n",
        "        mistakes.remove(1)\n",
        "    if distance_feet < distance_shoulder*1.5:\n",
        "      if 2 in mistakes:\n",
        "       mistakes.remove(2)\n",
        "\n",
        "    #Hands are pointing down - wrists under elbows - elbows under shoulder\n",
        "    if not(left_wrist[1] < left_elbow[1] and left_elbow[1] < left_shoulder[1] and left_wrist[1] < left_hip[1]):\n",
        "      if 3 in mistakes:\n",
        "        mistakes.remove(3)\n",
        "    if not(right_wrist[1] < right_elbow[1] and right_elbow[1] < right_shoulder[1] and right_wrist[1] < right_hip[1]):\n",
        "      if 4 in mistakes:\n",
        "        mistakes.remove(4)\n",
        "\n",
        "  #-------------------------------------------------------------------------\n",
        "  #3. check trophy phase ---------------------------------------------------\n",
        "  mistakes.extend([5,6,7,8,9,10])\n",
        "  for trophy_dict in trophy_dicts:\n",
        "    keypoints_trophy = trophy_dict['keypoints']\n",
        "    #keypoint order from https://github.com/MVIG-SJTU/AlphaPose/blob/master/docs/output.md\n",
        "    nose = (keypoints_trophy[0], keypoints_trophy[1])\n",
        "    left_eye = (keypoints_trophy[3], keypoints_trophy[4])\n",
        "    right_eye = (keypoints_trophy[6], keypoints_trophy[7])\n",
        "    left_ear = (keypoints_trophy[9], keypoints_trophy[10])\n",
        "    right_ear = (keypoints_trophy[12], keypoints_trophy[13])\n",
        "    left_shoulder = (keypoints_trophy[15], keypoints_trophy[16])\n",
        "    right_shoulder = (keypoints_trophy[18], keypoints_trophy[19])\n",
        "    left_elbow = (keypoints_trophy[21], keypoints_trophy[22])\n",
        "    right_elbow = (keypoints_trophy[24], keypoints_trophy[25])\n",
        "    left_wrist = (keypoints_trophy[27], keypoints_trophy[28])\n",
        "    right_wrist = (keypoints_trophy[30], keypoints_trophy[31])\n",
        "    left_hip = (keypoints_trophy[33], keypoints_trophy[34])\n",
        "    right_hip = (keypoints_trophy[36], keypoints_trophy[37])\n",
        "    left_knee = (keypoints_trophy[39], keypoints_trophy[40])\n",
        "    right_knee = (keypoints_trophy[42], keypoints_trophy[43])\n",
        "    left_ankle = (keypoints_trophy[45], keypoints_trophy[46])\n",
        "    right_ankle = (keypoints_trophy[48], keypoints_trophy[49])\n",
        "\n",
        "    # 2.1. 90° angle of right arm\n",
        "    elbow_wrist = np.array([right_wrist[0] - right_elbow[0], right_wrist[1] - right_elbow[1]])\n",
        "    elbow_shoulder = np.array([right_shoulder[0] - right_elbow[0], right_shoulder[1] - right_elbow[1]])\n",
        "    # Formula from https://www.cuemath.com/geometry/angle-between-vectors/\n",
        "    rad_angle = math.acos(np.dot(elbow_wrist,elbow_shoulder) / (np.linalg.norm(elbow_wrist) * np.linalg.norm(elbow_shoulder)))\n",
        "    deg_angle = rad_angle * ( 180.0 / math.pi)\n",
        "    if deg_angle < 80:\n",
        "      if 5 in mistakes:\n",
        "        mistakes.remove(5)\n",
        "    if deg_angle < 100:\n",
        "      if 6 in mistakes:\n",
        "        mistakes.remove(6)\n",
        "\n",
        "    # 2.2. left hand up\n",
        "    # 2.2.1. left wrist over nose\n",
        "    if left_wrist[1] < nose[1]:\n",
        "      if 7 in mistakes:\n",
        "        mistakes.remove(7)\n",
        "\n",
        "    # 2.2.2. angle of left arm between 90 and 180°\n",
        "    l_elbow_wrist = np.array([left_wrist[0] - left_elbow[0], left_wrist[1] - left_elbow[1]])\n",
        "    l_elbow_shoulder = np.array([left_shoulder[0] - left_elbow[0], left_shoulder[1] - left_elbow[1]])\n",
        "    rad_angle = math.acos(np.dot(l_elbow_wrist,l_elbow_shoulder) / (np.linalg.norm(l_elbow_wrist) * np.linalg.norm(l_elbow_shoulder)))\n",
        "    deg_angle = rad_angle * ( 180.0 / math.pi)\n",
        "    if deg_angle >= 90: #I guess stetching an arm over 180° is not possible!\n",
        "      if 8 in mistakes:\n",
        "        mistakes.remove(8)\n",
        "\n",
        "    # 2.3. bow of shoulder, hips and feet\n",
        "    # check if angle is smaller than 180°\n",
        "    r_hip_shoulder = np.array([right_shoulder[0] - right_hip[0], right_shoulder[1] - right_hip[1]])\n",
        "    r_hip_ankle = np.array([right_ankle[0] - right_hip[0], right_ankle[1] - right_hip[1]])\n",
        "    # Formula from https://www.cuemath.com/geometry/angle-between-vectors/\n",
        "    r_rad_angle = math.acos(np.dot(r_hip_shoulder,r_hip_ankle) / (np.linalg.norm(r_hip_shoulder) * np.linalg.norm(r_hip_ankle)))\n",
        "    r_deg_angle = r_rad_angle * (180.0 / math.pi)\n",
        "    if not (r_deg_angle > 180 and right_shoulder[0] > right_hip[0] and right_ankle[0] > right_hip[0]):\n",
        "      if 9 in mistakes:\n",
        "        mistakes.remove(9)\n",
        "\n",
        "    l_hip_shoulder = np.array([left_shoulder[0] - left_hip[0], left_shoulder[1] - left_hip[1]])\n",
        "    l_hip_ankle = np.array([left_ankle[0] - left_hip[0], left_ankle[1] - left_hip[1]])\n",
        "    l_rad_angle = math.acos(np.dot(l_hip_shoulder,l_hip_ankle) / (np.linalg.norm(l_hip_shoulder) * np.linalg.norm(l_hip_ankle)))\n",
        "    l_deg_angle = l_rad_angle * (180.0 / math.pi)\n",
        "    lower_bound = r_deg_angle * 0.9\n",
        "    upper_bound = r_deg_angle * 1.1\n",
        "    if l_deg_angle > lower_bound and l_deg_angle < upper_bound:\n",
        "      if 10 in mistakes:\n",
        "        mistakes.remove(10)\n",
        "\n",
        "  #-------------------------------------------------------------------------\n",
        "  #3. check acceleration phase ---------------------------------------------\n",
        "  mistakes.extend([11,12])\n",
        "  for acc_dict in acc_dicts:\n",
        "    keypoints_acc = acc_dict['keypoints']\n",
        "    #keypoint order from https://github.com/MVIG-SJTU/AlphaPose/blob/master/docs/output.md\n",
        "    nose = (keypoints_acc[0], keypoints_acc[1])\n",
        "    left_eye = (keypoints_acc[3], keypoints_acc[4])\n",
        "    right_eye = (keypoints_acc[6], keypoints_acc[7])\n",
        "    left_ear = (keypoints_acc[9], keypoints_acc[10])\n",
        "    right_ear = (keypoints_acc[12], keypoints_acc[13])\n",
        "    left_shoulder = (keypoints_acc[15], keypoints_acc[16])\n",
        "    right_shoulder = (keypoints_acc[18], keypoints_acc[19])\n",
        "    left_elbow = (keypoints_acc[21], keypoints_acc[22])\n",
        "    right_elbow = (keypoints_acc[24], keypoints_acc[25])\n",
        "    left_wrist = (keypoints_acc[27], keypoints_acc[28])\n",
        "    right_wrist = (keypoints_acc[30], keypoints_acc[31])\n",
        "    left_hip = (keypoints_acc[33], keypoints_acc[34])\n",
        "    right_hip = (keypoints_acc[36], keypoints_acc[37])\n",
        "    left_knee = (keypoints_acc[39], keypoints_acc[40])\n",
        "    right_knee = (keypoints_acc[42], keypoints_acc[43])\n",
        "    left_ankle = (keypoints_acc[45], keypoints_acc[46])\n",
        "    right_ankle = (keypoints_acc[48], keypoints_acc[49])\n",
        "\n",
        "    # 3.2. bow of shoulder, hips and feet\n",
        "    # check if angle is smaller than 180°\n",
        "    r_hip_shoulder = np.array([right_shoulder[0] - right_hip[0], right_shoulder[1] - right_hip[1]])\n",
        "    r_hip_ankle = np.array([right_ankle[0] - right_hip[0], right_ankle[1] - right_hip[1]])\n",
        "    r_rad_angle = math.acos(np.dot(r_hip_shoulder,r_hip_ankle) / (np.linalg.norm(r_hip_shoulder) * np.linalg.norm(r_hip_ankle)))\n",
        "    r_deg_angle = r_rad_angle * (180.0 / math.pi)\n",
        "    if r_deg_angle < 180 and right_shoulder[0] < right_hip[0] and right_ankle[0] < right_hip[0]:\n",
        "      if 11 in mistakes:\n",
        "        mistakes.remove(11)\n",
        "\n",
        "    l_hip_shoulder = np.array([left_shoulder[0] - left_hip[0], left_shoulder[1] - left_hip[1]])\n",
        "    l_hip_ankle = np.array([left_ankle[0] - left_hip[0], left_ankle[1] - left_hip[1]])\n",
        "    l_rad_angle = math.acos(np.dot(l_hip_shoulder,l_hip_ankle) / (np.linalg.norm(l_hip_shoulder) * np.linalg.norm(l_hip_ankle)))\n",
        "    l_deg_angle = l_rad_angle * (180.0 / math.pi)\n",
        "    lower_bound = r_deg_angle * 0.9\n",
        "    upper_bound = r_deg_angle * 1.1\n",
        "    if l_deg_angle > lower_bound and l_deg_angle < upper_bound:\n",
        "      if 12 in mistakes:\n",
        "        mistakes.remove(12)\n",
        "\n",
        "  #-------------------------------------------------------------------------\n",
        "  # 4. check contact point phase -------------------------------------------\n",
        "  mistakes.extend([13,14,15])\n",
        "  for contact_dict in contact_dicts:\n",
        "    keypoints_contact = contact_dict['keypoints']\n",
        "    #keypoint order from https://github.com/MVIG-SJTU/AlphaPose/blob/master/docs/output.md\n",
        "    nose = (keypoints_contact[0], keypoints_contact[1])\n",
        "    left_eye = (keypoints_contact[3], keypoints_contact[4])\n",
        "    right_eye = (keypoints_contact[6], keypoints_contact[7])\n",
        "    left_ear = (keypoints_contact[9], keypoints_contact[10])\n",
        "    right_ear = (keypoints_contact[12], keypoints_contact[13])\n",
        "    left_shoulder = (keypoints_contact[15], keypoints_contact[16])\n",
        "    right_shoulder = (keypoints_contact[18], keypoints_contact[19])\n",
        "    left_elbow = (keypoints_contact[21], keypoints_contact[22])\n",
        "    right_elbow = (keypoints_contact[24], keypoints_contact[25])\n",
        "    left_wrist = (keypoints_contact[27], keypoints_contact[28])\n",
        "    right_wrist = (keypoints_contact[30], keypoints_contact[31])\n",
        "    left_hip = (keypoints_contact[33], keypoints_contact[34])\n",
        "    right_hip = (keypoints_contact[36], keypoints_contact[37])\n",
        "    left_knee = (keypoints_contact[39], keypoints_contact[40])\n",
        "    right_knee = (keypoints_contact[42], keypoints_contact[43])\n",
        "    left_ankle = (keypoints_contact[45], keypoints_contact[46])\n",
        "    right_ankle = (keypoints_contact[48], keypoints_contact[49])\n",
        "\n",
        "    # 4.1. straight arm - angle between shoulder - elbow - wrist = 180°\n",
        "    elbow_wrist = np.array([right_wrist[0] - right_elbow[0], right_wrist[1] - right_elbow[1]])\n",
        "    elbow_shoulder = np.array([right_shoulder[0] - right_elbow[0], right_shoulder[1] - right_elbow[1]])\n",
        "    rad_angle = math.acos(np.dot(elbow_wrist,elbow_shoulder) / (np.linalg.norm(elbow_wrist) * np.linalg.norm(elbow_shoulder)))\n",
        "    deg_angle = rad_angle * (180.0 / math.pi)\n",
        "    if deg_angle > 160:\n",
        "      if 13 in mistakes:\n",
        "        mistakes.remove(13)\n",
        "\n",
        "    # 4.2. hitting point at maximum height (not sure, how to do that)  (TODO - ask Sebastian)\n",
        "    #check if legs are also stretched\n",
        "    #left leg\n",
        "    left_knee_ankle = np.array([left_knee[0] - left_ankle[0], left_knee[1] - left_ankle[1]])\n",
        "    left_knee_hip = np.array([left_knee[0] - left_hip[0], left_knee[1] - left_hip[1]])\n",
        "    rad_angle = math.acos(np.dot(left_knee_ankle,left_knee_hip) / (np.linalg.norm(left_knee_ankle) * np.linalg.norm(left_knee_hip)))\n",
        "    deg_angle = rad_angle * (180.0 / math.pi)\n",
        "    if deg_angle > 165:\n",
        "      if 14 in mistakes:\n",
        "        mistakes.remove(14)\n",
        "\n",
        "    #right leg\n",
        "    right_knee_ankle = np.array([right_knee[0] - right_ankle[0], right_knee[1] - right_ankle[1]])\n",
        "    right_knee_hip = np.array([right_knee[0] - right_hip[0], right_knee[1] - right_hip[1]])\n",
        "    rad_angle = math.acos(np.dot(right_knee_ankle,right_knee_hip) / (np.linalg.norm(right_knee_ankle) * np.linalg.norm(right_knee_hip)))\n",
        "    deg_angle = rad_angle * (180.0 / math.pi)\n",
        "    if deg_angle > 165:\n",
        "      if 15 in mistakes:\n",
        "        mistakes.remove(15)\n",
        "\n",
        "  #-------------------------------------------------------------------------\n",
        "  # 5. check finish phase --------------------------------------------------\n",
        "\n",
        "  #angles from contact point phase to compare with angle from finish phase\n",
        "  prev_l_knee_ankle = np.array([left_ankle[0] - left_knee[0], left_ankle[1] - left_knee[1]])\n",
        "  prev_l_knee_hip = np.array([left_knee[0] - left_hip[0], left_knee[1] - left_hip[1]])\n",
        "  prev_l_rad_angle = math.acos(np.dot(prev_l_knee_ankle,prev_l_knee_hip) / (np.linalg.norm(prev_l_knee_ankle) * np.linalg.norm(prev_l_knee_hip)))\n",
        "  prev_l_deg_angle = prev_l_rad_angle * (180.0 / math.pi)\n",
        "\n",
        "  prev_r_knee_ankle = np.array([right_ankle[0] - right_knee[0], right_ankle[1] - right_knee[1]])\n",
        "  prev_r_knee_hip = np.array([right_knee[0] - right_hip[0], right_knee[1] - right_hip[1]])\n",
        "  prev_r_rad_angle = math.acos(np.dot(prev_r_knee_ankle,prev_r_knee_hip) / (np.linalg.norm(prev_r_knee_ankle) * np.linalg.norm(prev_r_knee_hip)))\n",
        "  prev_r_deg_angle = prev_r_rad_angle * (180.0 / math.pi)\n",
        "\n",
        "  mistakes.append(16)\n",
        "  for finish_dict in finish_dicts:\n",
        "    keypoints_finish = finish_dict['keypoints']\n",
        "    #keypoint order from https://github.com/MVIG-SJTU/AlphaPose/blob/master/docs/output.md\n",
        "    nose = (keypoints_finish[0], keypoints_finish[1])\n",
        "    left_eye = (keypoints_finish[3], keypoints_finish[4])\n",
        "    right_eye = (keypoints_finish[6], keypoints_finish[7])\n",
        "    left_ear = (keypoints_finish[9], keypoints_finish[10])\n",
        "    right_ear = (keypoints_finish[12], keypoints_finish[13])\n",
        "    left_shoulder = (keypoints_finish[15], keypoints_finish[16])\n",
        "    right_shoulder = (keypoints_finish[18], keypoints_finish[19])\n",
        "    left_elbow = (keypoints_finish[21], keypoints_finish[22])\n",
        "    right_elbow = (keypoints_finish[24], keypoints_finish[25])\n",
        "    left_wrist = (keypoints_finish[27], keypoints_finish[28])\n",
        "    right_wrist = (keypoints_finish[30], keypoints_finish[31])\n",
        "    left_hip = (keypoints_finish[33], keypoints_finish[34])\n",
        "    right_hip = (keypoints_finish[36], keypoints_finish[37])\n",
        "    left_knee = (keypoints_finish[39], keypoints_finish[40])\n",
        "    right_knee = (keypoints_finish[42], keypoints_finish[43])\n",
        "    left_ankle = (keypoints_finish[45], keypoints_finish[46])\n",
        "    right_ankle = (keypoints_finish[48], keypoints_finish[49])\n",
        "\n",
        "    # 5.1. bend knees\n",
        "    left_knee_ankle = np.array([left_ankle[0] - left_knee[0], left_ankle[1] - left_knee[1]])\n",
        "    left_knee_hip = np.array([left_knee[0] - left_hip[0], left_knee[1] - left_hip[1]])\n",
        "    l_rad_angle = math.acos(np.dot(left_knee_ankle,left_knee_hip) / (np.linalg.norm(left_knee_ankle) * np.linalg.norm(left_knee_hip)))\n",
        "    l_deg_angle = l_rad_angle * (180.0 / math.pi)\n",
        "\n",
        "    right_knee_ankle = np.array([right_ankle[0] - right_knee[0], right_ankle[1] - right_knee[1]])\n",
        "    right_knee_hip = np.array([right_knee[0] - right_hip[0], right_knee[1] - right_hip[1]])\n",
        "    r_rad_angle = math.acos(np.dot(right_knee_ankle,right_knee_hip) / (np.linalg.norm(right_knee_ankle) * np.linalg.norm(right_knee_hip)))\n",
        "    r_deg_angle = r_rad_angle * (180.0 / math.pi)\n",
        "\n",
        "    # compare bending to previous ones\n",
        "    left_bound = prev_l_deg_angle * 0.85\n",
        "    right_bound = prev_r_deg_angle * 0.85\n",
        "    if left_bound < l_deg_angle and right_bound < prev_r_deg_angle:\n",
        "      if 16 in mistakes:\n",
        "        mistakes.remove(16)\n",
        "\n",
        "checkPosition()\n"
      ],
      "metadata": {
        "id": "s652X_ulXlYF"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate final output video:"
      ],
      "metadata": {
        "id": "N6cyZiZb3Os4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "long_nr = str('{:03d}'.format(video_nr))\n",
        "video_path = 'input/video' + long_nr + '.mp4'\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "if video.isOpened():\n",
        "  nr_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  fps = video.get(cv2.CAP_PROP_FPS)\n",
        "  width = int(video.get(3))\n",
        "  height = int(video.get(4))\n",
        "  resolution = (width, height)\n",
        "  print(f\"Resolution: {width}x{height}\")\n",
        "\n",
        "  out_video_path = 'output/annotated_video' + long_nr + '.mp4'\n",
        "  out_file = cv2.VideoWriter(out_video_path, cv2.VideoWriter_fourcc(*'mp4v'), 7, (width, height))\n",
        "\n",
        "  with open('output/alphapose-results.json') as json_result:\n",
        "      data = json.load(json_result)  #list of dictionaries\n",
        "\n",
        "  counter = 0\n",
        "  thickness = 3\n",
        "  radius_0 = None\n",
        "  radius_1_2 = None\n",
        "  radius_7 = None\n",
        "  while True:\n",
        "    success, frame = video.read()\n",
        "    if not success:\n",
        "      break\n",
        "    keypoints = data[counter]['keypoints']\n",
        "    if counter >= s_start and counter < s_trophy:\n",
        "      #check error codes 0,1,2,3,4\n",
        "      text = []\n",
        "      if (1 in mistakes) or (2 in mistakes):\n",
        "        left_ankle = (keypoints[45], keypoints[46])\n",
        "        right_ankle = (keypoints[48], keypoints[49])\n",
        "        center = (int(min(right_ankle[0], left_ankle[0]) + abs(right_ankle[0] - left_ankle[0])/2),\n",
        "                  int(min(right_ankle[1], left_ankle[1]) + abs(right_ankle[1] - left_ankle[1])/2))\n",
        "        if radius_1_2 == None:\n",
        "          radius_1_2 = (int(abs(right_ankle[0] - left_ankle[0]) * 1.1), int((keypoints[46] - keypoints[40])/2.0))\n",
        "        angle = 0\n",
        "        color = (84, 139, 84) # green in BGR\n",
        "        frame = cv2.ellipse(frame, center, radius_1_2, 0, 0, 360, color, thickness)\n",
        "        # add text\n",
        "        text.append((color, \"Your feet should be slightly wider\"))\n",
        "        text.append((color, \"than shoulder-width apart.\"))\n",
        "      else:\n",
        "        text.append(((0,0,0),\"Your feet have an ideal distance.\"))\n",
        "\n",
        "      if 0 in mistakes:\n",
        "        left_ankle = (int(keypoints[45]), int(keypoints[46]))\n",
        "        if radius_0 == None:\n",
        "          radius_0 = int((keypoints[46] - keypoints[40])/2.0) #(left_ankle.y - left_knee.y) / 2\n",
        "        color = (0, 165, 255) # orange in BGR\n",
        "        frame = cv2.circle(frame, left_ankle, radius_0, color, thickness)\n",
        "        text.append((color,\"Your left foot should be in front\"))\n",
        "        text.append((color,\"of the right one.\"))\n",
        "      else:\n",
        "        text.append(((0,0,0), \"Your left foot is positioned correctly.\"))\n",
        "\n",
        "      if 3 in mistakes:\n",
        "        color = (57, 79, 205)\n",
        "        left_shoulder = (int(keypoints[15]), int(keypoints[16]))\n",
        "        left_elbow = (int(keypoints[21]), int(keypoints[22]))\n",
        "        left_wrist = (int(keypoints[27]), int(keypoints[28]))\n",
        "        frame = cv2.line(frame, left_shoulder, left_elbow, color, thickness)\n",
        "        frame = cv2.line(frame, left_elbow, left_wrist, color, thickness)\n",
        "        text.append((color,\"Let your left arm dangle!\"))\n",
        "      else:\n",
        "        text.append(((0,0,1), \"The position of your left arm\"))\n",
        "        text.append(((0,0,1), \"is perfect.\"))\n",
        "\n",
        "      if 4 in mistakes:\n",
        "        color = (237, 149, 100)\n",
        "        right_shoulder = (int(keypoints[18]), int(keypoints[19]))\n",
        "        right_elbow = (int(keypoints[24]), int(keypoints[25]))\n",
        "        right_wrist = (int(keypoints[30]), int(keypoints[31]))\n",
        "        frame = cv2.line(frame, right_shoulder, right_elbow, color, thickness)\n",
        "        frame = cv2.line(frame, right_elbow, right_wrist, color, thickness)\n",
        "        text.append((color, \"Let your right arm dangle!\"))\n",
        "      else:\n",
        "        text.append(((0,0,2), \"The position of your right arm\"))\n",
        "        text.append(((0,0,2), \"is perfect.\"))\n",
        "\n",
        "      frame_cpy = frame.copy()\n",
        "      vspace = height * 0.03\n",
        "      hspace = width * 0.04\n",
        "      frame = cv2.rectangle(frame, (int(width*2/3), int(height*2/3)), (width, height), (222, 222, 222), cv2.FILLED)\n",
        "      vadd = 0\n",
        "      for i, (c,t) in enumerate(text):\n",
        "        if(i> 0 and c != (0,0,0) and c == text[i-1][0]):\n",
        "          vadd += vspace\n",
        "        else:\n",
        "          vadd += vspace*2\n",
        "          if(c == (0,0,0) or  c == (0,0,1) or c == (0,0,2)):\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, 1)\n",
        "          else:\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, cv2.FILLED)\n",
        "        frame = cv2.putText(frame, t, (int(width*2/3+hspace), int(height*2/3+vadd)), cv2.FONT_HERSHEY_DUPLEX, 0.6, (22, 22, 22), 1)\n",
        "      alpha = 0.7\n",
        "      frame=cv2.addWeighted(frame, alpha, frame_cpy,1-alpha, gamma=0)\n",
        "    #---------------------------------------------------------------------------\n",
        "    elif counter >= s_trophy and counter < s_acc:\n",
        "      #check error codes 5,6,7,8,9,10\n",
        "      text = []\n",
        "      if 5 in mistakes or 6 in mistakes:\n",
        "        color = (237, 149, 100)\n",
        "        right_shoulder = (int(keypoints[18]), int(keypoints[19]))\n",
        "        right_elbow = (int(keypoints[24]), int(keypoints[25]))\n",
        "        right_wrist = (int(keypoints[30]), int(keypoints[31]))\n",
        "        frame = cv2.line(frame, right_shoulder, right_elbow, color, thickness)\n",
        "        frame = cv2.line(frame, right_elbow, right_wrist, color, thickness)\n",
        "        text.append((color, \"Your right arm should be in\"))\n",
        "        text.append((color, \"a 90 degree angle.\"))\n",
        "      else:\n",
        "        text.append(((0,0,0), \"Your right arm has an ideal angle.\"))\n",
        "\n",
        "      if 7 in mistakes:\n",
        "        left_wrist = (int(keypoints[27]), int(keypoints[28]))\n",
        "        if radius_7 == None:\n",
        "          radius_7 = int((keypoints[46] - keypoints[40])/2.0) #(left_ankle.y - left_knee.y) / 2\n",
        "        color = (0, 165, 255) # orange in BGR\n",
        "        frame = cv2.circle(frame, left_wrist, radius_7, color, thickness)\n",
        "        text.append((color, \"Your left arm should be up.\"))\n",
        "      else:\n",
        "        text.append(((0,0,0), \"Your left arm has an ideal position.\"))\n",
        "\n",
        "      if 8 in mistakes:\n",
        "        color = (57, 79, 205)\n",
        "        left_shoulder = (int(keypoints[15]), int(keypoints[16]))\n",
        "        left_elbow = (int(keypoints[21]), int(keypoints[22]))\n",
        "        left_wrist = (int(keypoints[27]), int(keypoints[28]))\n",
        "        frame = cv2.line(frame, left_shoulder, left_elbow, color, thickness)\n",
        "        frame = cv2.line(frame, left_elbow, left_wrist, color, thickness)\n",
        "        text.append((color, \"Stretch your left arm more.\"))\n",
        "      else:\n",
        "        text.append(((0,0,0), \"Your left arm is correctly stretched.\"))\n",
        "\n",
        "      if 9 in mistakes: # or 10 in mistakes:\n",
        "        pt_x = []\n",
        "        pt_y = []\n",
        "        right_shoulder = (keypoints[18], keypoints[19])\n",
        "        right_hip = (keypoints[36], keypoints[37])\n",
        "        right_ankle = (keypoints[48], keypoints[49])\n",
        "        #Bézier curves\n",
        "        for t in np.linspace(0, 1, 100):\n",
        "          x = (1 - t)**2 * right_shoulder[0] + 2 * (1 - t) * t * right_hip[0] + t**2 * right_ankle[0]\n",
        "          y = (1 - t)**2 * right_shoulder[1] + 2 * (1 - t) * t * right_hip[1] + t**2 * right_ankle[1]\n",
        "          pt_x.append(int(x))\n",
        "          pt_y.append(int(y))\n",
        "        pt = np.concatenate((np.array(pt_x).reshape(-1, 1), np.array(pt_y).reshape(-1, 1)), axis=1)\n",
        "        #https://www.geeksforgeeks.org/python-opencv-cv2-polylines-method/\n",
        "        color = (205, 82, 180) # green in BGR\n",
        "        frame = cv2.polylines(frame, [pt.reshape((-1, 1, 2))], False, color, thickness)\n",
        "        text.append((color, \"Tilt your body more backward.\"))\n",
        "      else:\n",
        "        text.append(((0,0,0), \"You have an ideal posture.\"))\n",
        "\n",
        "      frame_cpy = frame.copy()\n",
        "      vspace = height * 0.03\n",
        "      hspace = width * 0.04\n",
        "      frame = cv2.rectangle(frame, (int(width*2/3), int(height*2/3)), (width, height), (222, 222, 222), cv2.FILLED)\n",
        "      vadd = 0\n",
        "      for i, (c,t) in enumerate(text):\n",
        "        if(i> 0 and c != (0,0,0) and c == text[i-1][0]):\n",
        "          vadd += vspace\n",
        "        else:\n",
        "          vadd += vspace*2\n",
        "          if(c == (0,0,0)):\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, 1)\n",
        "          else:\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, cv2.FILLED)\n",
        "        frame = cv2.putText(frame, t, (int(width*2/3+hspace), int(height*2/3+vadd)), cv2.FONT_HERSHEY_DUPLEX, 0.6, (22, 22, 22), 1)\n",
        "      alpha = 0.7\n",
        "      frame=cv2.addWeighted(frame, alpha, frame_cpy,1-alpha, gamma=0)\n",
        "\n",
        "    elif counter >= s_acc and counter < s_contact:\n",
        "      #check error codes 11, 12\n",
        "      text = []\n",
        "      if 11 in mistakes: # or 12 not in mistakes:\n",
        "        pt_x = []\n",
        "        pt_y = []\n",
        "        right_shoulder = (keypoints[18], keypoints[19])\n",
        "        right_hip = (keypoints[36], keypoints[37])\n",
        "        right_ankle = (keypoints[48], keypoints[49])\n",
        "        #Bézier curves\n",
        "        for t in np.linspace(0, 1, 100):\n",
        "          x = (1 - t)**2 * right_shoulder[0] + 2 * (1 - t) * t * right_hip[0] + t**2 * right_ankle[0]\n",
        "          y = (1 - t)**2 * right_shoulder[1] + 2 * (1 - t) * t * right_hip[1] + t**2 * right_ankle[1]\n",
        "          pt_x.append(int(x))\n",
        "          pt_y.append(int(y))\n",
        "        pt = np.concatenate((np.array(pt_x).reshape(-1, 1), np.array(pt_y).reshape(-1, 1)), axis=1)\n",
        "        #https://www.geeksforgeeks.org/python-opencv-cv2-polylines-method/\n",
        "        color = (205, 82, 180) # green in BGR\n",
        "        frame = cv2.polylines(frame, [pt.reshape((-1, 1, 2))], False, color, thickness)\n",
        "        text.append((color, \"Tilt your body more backward.\"))\n",
        "      else:\n",
        "        text.append(((0,0,0), \"You have an ideal posture.\"))\n",
        "\n",
        "      frame_cpy = frame.copy()\n",
        "      vspace = height * 0.03\n",
        "      hspace = width * 0.04\n",
        "      frame = cv2.rectangle(frame, (int(width*2/3), int(height*2/3)), (width, height), (222, 222, 222), cv2.FILLED)\n",
        "      vadd = 0\n",
        "      for i, (c,t) in enumerate(text):\n",
        "        if(i> 0 and c != (0,0,0) and c == text[i-1][0]):\n",
        "          vadd += vspace\n",
        "        else:\n",
        "          vadd += vspace*2\n",
        "          if(c == (0,0,0)):\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, 1)\n",
        "          else:\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, cv2.FILLED)\n",
        "        frame = cv2.putText(frame, t, (int(width*2/3+hspace), int(height*2/3+vadd)), cv2.FONT_HERSHEY_DUPLEX, 0.6, (22, 22, 22), 1)\n",
        "      alpha = 0.7\n",
        "      frame=cv2.addWeighted(frame, alpha, frame_cpy,1-alpha, gamma=0)\n",
        "\n",
        "    elif counter >= s_contact and counter < s_finish:\n",
        "      #check error codes 13, 14, 15\n",
        "      text = []\n",
        "      if 13 in mistakes:\n",
        "        color = (205, 82, 180)\n",
        "        right_shoulder = (int(keypoints[18]), int(keypoints[19]))\n",
        "        right_elbow = (int(keypoints[24]), int(keypoints[25]))\n",
        "        right_wrist = (int(keypoints[30]), int(keypoints[31]))\n",
        "        frame = cv2.line(frame, right_shoulder, right_elbow, color, thickness)\n",
        "        frame = cv2.line(frame, right_elbow, right_wrist, color, thickness)\n",
        "        text.append((color, \"Keep your right arm straight!\"))\n",
        "      else:\n",
        "        text.append(((0,0,1), \"You kept your right arm\"))\n",
        "        text.append(((0,0,1), \"perfectly straight.\"))\n",
        "\n",
        "      if 14 in mistakes:\n",
        "        color = (57, 79, 205)\n",
        "        left_hip = (int(keypoints[33]), int(keypoints[34]))\n",
        "        left_knee = (int(keypoints[39]), int(keypoints[40]))\n",
        "        left_ankle = (int(keypoints[45]), int(keypoints[46]))\n",
        "        frame = cv2.line(frame, left_hip, left_knee, color, thickness)\n",
        "        frame = cv2.line(frame, left_knee, left_ankle, color, thickness)\n",
        "        text.append((color, \"Stretch your left leg more!\"))\n",
        "      else:\n",
        "        text.append(((0,0,2), \"You kept your left leg\"))\n",
        "        text.append(((0,0,2), \"perfectly straight.\"))\n",
        "\n",
        "      if 15 in mistakes:\n",
        "        color = (237, 149, 100)\n",
        "        right_hip = (int(keypoints[36]), int(keypoints[37]))\n",
        "        right_knee = (int(keypoints[42]), int(keypoints[43]))\n",
        "        right_ankle = (int(keypoints[48]), int(keypoints[49]))\n",
        "        frame = cv2.line(frame, right_hip, right_knee, color, thickness)\n",
        "        frame = cv2.line(frame, right_knee, right_ankle, color, thickness)\n",
        "        text.append((color, \"Stretch your right leg more!\"))\n",
        "      else:\n",
        "        text.append(((0,0,3), \"You kept your right leg\"))\n",
        "        text.append(((0,0,3), \"perfectly straight.\"))\n",
        "\n",
        "      frame_cpy = frame.copy()\n",
        "      vspace = height * 0.03\n",
        "      hspace = width * 0.04\n",
        "      frame = cv2.rectangle(frame, (int(width*2/3), int(height*2/3)), (width, height), (222, 222, 222), cv2.FILLED)\n",
        "      vadd = 0\n",
        "      for i, (c,t) in enumerate(text):\n",
        "        if(i> 0 and c != (0,0,0) and c == text[i-1][0]):\n",
        "          vadd += vspace\n",
        "        else:\n",
        "          vadd += vspace*2\n",
        "          if(c == (0,0,0) or c == (0,0,1) or c == (0,0,2) or c == (0,0,3)):\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, 1)\n",
        "          else:\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, cv2.FILLED)\n",
        "        frame = cv2.putText(frame, t, (int(width*2/3+hspace), int(height*2/3+vadd)), cv2.FONT_HERSHEY_DUPLEX, 0.6, (22, 22, 22), 1)\n",
        "      alpha = 0.7\n",
        "      frame=cv2.addWeighted(frame, alpha, frame_cpy,1-alpha, gamma=0)\n",
        "\n",
        "    elif counter >= s_finish and counter < e_finish:\n",
        "      #check error codes 18\n",
        "      text = []\n",
        "      if 16 in mistakes:\n",
        "        left_hip = (int(keypoints[33]), int(keypoints[34]))\n",
        "        left_knee = (int(keypoints[39]), int(keypoints[40]))\n",
        "        left_ankle = (int(keypoints[45]), int(keypoints[46]))\n",
        "        right_hip = (int(keypoints[36]), int(keypoints[37]))\n",
        "        right_knee = (int(keypoints[42]), int(keypoints[43]))\n",
        "        right_ankle = (int(keypoints[48]), int(keypoints[49]))\n",
        "        color = (57, 79, 205)\n",
        "        frame = cv2.line(frame, left_hip, left_knee, color, thickness)\n",
        "        frame = cv2.line(frame, left_knee, left_ankle, color, thickness)\n",
        "        color = (237, 149, 100)\n",
        "        frame = cv2.line(frame, right_hip, right_knee, color, thickness)\n",
        "        frame = cv2.line(frame, right_knee, right_ankle, color, thickness)\n",
        "        text.append((color, \"Bend your knees more after\"))\n",
        "        text.append((color, \"jumping to protect your knees.\"))\n",
        "      else:\n",
        "        text.append(((0,0,0), \"Nice jump!\"))\n",
        "\n",
        "      frame_cpy = frame.copy()\n",
        "      vspace = height * 0.03\n",
        "      hspace = width * 0.04\n",
        "      frame = cv2.rectangle(frame, (int(width*2/3), int(height*2/3)), (width, height), (222, 222, 222), cv2.FILLED)\n",
        "      vadd = 0\n",
        "      for i, (c,t) in enumerate(text):\n",
        "        if(i> 0 and c != (0,0,0) and c == text[i-1][0]):\n",
        "          vadd += vspace\n",
        "        else:\n",
        "          vadd += vspace*2\n",
        "          if(c == (0,0,0)):\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, 1)\n",
        "          else:\n",
        "            frame = cv2.circle(frame, (int(width*2/3+(hspace/2)), int(height*2/3+vadd-vspace/4)), int(vspace/2), c, cv2.FILLED)\n",
        "        frame = cv2.putText(frame, t, (int(width*2/3+hspace), int(height*2/3+vadd)), cv2.FONT_HERSHEY_DUPLEX, 0.6, (22, 22, 22), 1)\n",
        "      alpha = 0.7\n",
        "      frame=cv2.addWeighted(frame, alpha, frame_cpy,1-alpha, gamma=0)\n",
        "\n",
        "    out_file.write(frame)\n",
        "    counter += 1\n",
        "\n",
        "  # Release video capture and writer objects\n",
        "  video.release()\n",
        "  out_file.release()\n",
        "\n",
        "# Closes all the frames\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Bf9ZsCCFj1kX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46a4f3d-773d-469b-aab1-0c64d45457be"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not recognize phases\n",
            "Could not recognize phases\n",
            "Could not recognize phases\n",
            "Could not recognize phases\n",
            "Could not recognize phases\n",
            "Could not recognize phases\n",
            "Could not recognize phases\n",
            "No Tennis Racket detected in the given image\n",
            "No Tennis Racket detected in the given image\n",
            "No Tennis Racket detected in the given image\n",
            "No Tennis Racket detected in the given image\n",
            "['start', 'start', 'start', 'start', 'start', 'start', 'start', 'start', 'start', 'start', 'start', 'start', 'start', 'start', None, None, None, None, None, None, None, 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', 'loading', None, 'acceleration', 'acceleration', 'acceleration', 'acceleration', 'contact', 'contact', 'contact', 'contact', 'contact', 'finish', 'finish', 'finish', 'finish', 'finish', 'finish', 'finish', 'finish', None, None, None]\n",
            "/content/TennisCoach/AlphaPose\n",
            "Resolution: 1280x720\n"
          ]
        }
      ]
    }
  ]
}